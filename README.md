# Hindi Pluralization: A Comparison of CRF and LSTM Models

## Abstract

This project explores the task of Hindi pluralization using two machine learning models: Conditional Random Fields (CRF) and Long Short-Term Memory (LSTM) networks. Hindi is a morphologically rich language, and pluralization plays a key role in its grammar. By training both models on the UniMorph dataset, we evaluate their ability to predict plural forms of Hindi words.

While CRF focuses on word endings and follows structured rules, LSTM attempts to learn patterns from entire word sequences. This comparison helps identify which model performs better for this task and under what conditions.

---

## üß™ Research Questions

- Which model performs better (CRF or LSTM)?
- What are the strengths and weaknesses of each model?
- What are the possible future improvements for both?

---

## üìö Introduction

Pluralization refers to making a word express more than one object or subject. In Hindi, pluralization can be complex and may not follow a fixed pattern. Some masculine nouns change endings (`‡§≤‡§°‡§º‡§ï‡§æ ‚Üí ‡§≤‡§°‡§º‡§ï‡•á`), some feminine nouns adopt different suffixes (`‡§ï‡§ø‡§§‡§æ‡§¨ ‚Üí ‡§ï‡§ø‡§§‡§æ‡§¨‡•á‡§Ç`), while others remain unchanged or follow irregular patterns.

- **CRF** learns patterns by focusing on word endings and uses a structured rule-based approach.
- **LSTM** learns entire word structures and captures character-level patterns over time.

---

## üîç Related Work

- **Rule-based methods** use predefined grammar rules to transform words.
- **Data-driven models** like CRF and LSTM learn transformations from data.

Our work builds on previous research, such as the rule-based "Hindi Morphological Analyzer and Generator", but focuses on machine learning models trained using real data from the UniMorph project.

---

## üìÅ Dataset Handling & Preprocessing

- **Dataset Source:** [UniMorph Project](https://unimorph.github.io/)
- **CRF Pipeline:** Uses `pandas` for structured processing, performs one-hot encoding, applies grid search for hyperparameter tuning.
- **LSTM Pipeline:** Uses manual processing and alignment-based transformations, does not rely on one-hot encoding or grid search.

---

## ‚öôÔ∏è Experiment Setup

Three phases were followed:
1. **Preprocessing** ‚Äì Cleaning and structuring the dataset.
2. **Training** ‚Äì Hyperparameter tuning and sanity checks.
3. **Evaluation** ‚Äì Metrics like accuracy, precision, recall, and F1-score.

---

## üìä Results

### üî∑ CRF Model

- **Training data:** 37,564 instances
- **Test data:** 16,100 instances

| Label     | Precision | Recall | F1-score |
|-----------|-----------|--------|----------|
| Plural    | 0.925     | 0.939  | 0.932    |
| Singular  | 0.938     | 0.924  | 0.931    |

**Accuracy:** 93.2%

**Common Errors:**
- Cannot handle context-dependent words.
- Fails in multi-word complex sentences.

---

### üî∂ LSTM Model

- **Training data:** 42,931 instances
- **Test data:** 10,733 instances

| Label     | Precision | Recall | F1-score |
|-----------|-----------|--------|----------|
| Plural    | 0.917     | 0.878  | 0.897    |
| Singular  | 0.879     | 0.917  | 0.898    |

**Accuracy:** 89.7%

**Common Errors:**
- Fails on rare words.
- Suffers from overfitting.

---

## ‚öñÔ∏è Comparison

| Metric     | CRF    | LSTM   |
|------------|--------|--------|
| Accuracy   | 93.2%  | 89.7%  |
| Strength   | Learns rules | Learns patterns |
| Weakness   | No context | Overfitting on small data |

CRF performed slightly better due to Hindi‚Äôs rule-based plural patterns and smaller dataset size.

---

## ‚úÖ Conclusion

- **CRF** performs better on smaller datasets and predictable patterns.
- **LSTM** requires larger datasets but can learn complex transformations.

Both models are valuable for developing morphological tools for Hindi and other inflectional languages.

---

## üîÆ Future Work

- Add more diverse datasets beyond UniMorph.
- Use data augmentation (e.g., synthetic word generation).
- Experiment with hybrid models (CRF + LSTM).

---

## üìö References

1. Cambridge Dictionary. "Pluralize." [https://dictionary.cambridge.org/us/dictionary/english/pluralize](https://dictionary.cambridge.org/us/dictionary/english/pluralize)  
2. Agarwal, A. et al. (2014). "Morphological Analyser for Hindi ‚Äì A Rule-Based Implementation."  
3. OpenAI. "ChatGPT: A Large Language Model." [https://openai.com/chatgpt](https://openai.com/chatgpt)  
4. Generated by a Python script from the implemented code.  
5. Evaluation metrics computed from CRF and LSTM model experiments.  
6. Hochreiter, S., Schmidhuber, J. (1997). "Long Short-Term Memory." *Neural Computation*, 9(8), 1735‚Äì1780.  
7. Graves, A. (2013). "Generating Sequences With Recurrent Neural Networks." *arXiv preprint arXiv:1308.0850.*  
8. Lafferty, J., McCallum, A., Pereira, F. (2001). "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data." *Proc. of ICML*, 2001.  
9. Sutton, C., McCallum, A. (2012). "An Introduction to Conditional Random Fields." *Foundations and Trends in Machine Learning*, 4(4), 267‚Äì373.  
10. UniMorph. "The Universal Morphology Project." [https://unimorph.github.io/](https://unimorph.github.io/)

---

